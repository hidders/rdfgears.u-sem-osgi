#
# The following parameter indicates where RDFGears
# looks for the data folders, and you might need to modify it
# since your application server's current directory might vary
# if you launch Tomcat from the bin directory, it should be fine 

rdfgears.base.path = ../rdfgears/

#
# The following paths are relative to the base path, 
# and you should not need to modify them.
# You need to make sure that these directories exist
# (in case you can create them empty)
# An empty value of the parameter means it points to the base path
#
workflows.path = data/workflows
processors.path = data/processors
functions.path = data/functions
repository.path = pluginRepository
hbm.path = hbm
data.types.path = dataTypes


rdfgears.rest.URL = /rdfgears-rest


lexicon.path = lexicon
language.profile.path = imreal-language-profiles
flickr.data.path = flickrdata
hofstede.file.path = 
region.file.path = 
value.storage.path = 
twitter.data.path = twitterData
#
# specify the debug level with which RDF Gears is executed.
# levels are ALL / DEBUG / INFO / WARN / ERROR / FATAL / OFF / TRACE as per log4j
#
log.level = FATAL

#
# Credentials for the database and the Flickr APIs
#
flickr.api.key = 

database = localhost/imreal
dbuser = 
dbpassword = 

# remember to grant rights to the user on the table
# CREATE USER '<dbuser>'@'localhost' IDENTIFIED BY '<dbpassword>'; 
# CREATE DATABASE IF NOT EXISTS `<dbname>` ;
# GRANT ALL PRIVILEGES ON `<dbname>`.* TO '<dbuser>'@'localhost';

entity.database.url = jdbc:mysql://localhost:3306/entityData

entity.dbuser = 

entity.dbpassword = 

twitter.OAuth.consumer.key = 
twitter.OAuth.consumer.secret = 
twitter.OAuth.access.token = 
twitter.OAuth.access.secret = 

# INTERNAL PARAMETERS

#
# page size for remote queries
# if batchsize>0, remote sparql endpoints will be queried repetitively 
# with batchsize as LIMIT, and a shifting OFFSET.
# Note that this works for select only because of practical virtuoso 
# implementation issues, and for construct it doesn't work reliably at 
# all.  
# Set to 0 to disable batched querying
remote.sparql.select.batchsize = 000
remote.sparql.construct.batchsize = 0

# max number of remote sparql retries
sparql.retry.max = 3
# pause between retries (in milliseconds)
sparql.retry.pause = 2000

#greedy.loading.of.remote.queries = false
greedy.loading.of.remote.queries = true



#########################################################################3
# Make workflow execution order more predictable. Useful for debugging. 
# 
# Completely disable laziness for all functions. 
# makes execution order more predictable. Laziness is enabled by default. 
#disable.laziness = true
# 
# Disable pipelining to generate all bag elements before passing it to the
# next function. It is enabled by default. 
# In the current implementation it effectively disables laziness, too, although
# lazyvalues will still be instantiated
#disable.pipelining = true

